{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.  1.  2.  3.  4.  5.]\n",
      " [ 1.  0.  1.  2.  3.  4.]\n",
      " [ 2.  1.  1.  2.  3.  4.]\n",
      " [ 3.  2.  2.  2.  2.  3.]\n",
      " [ 4.  3.  3.  3.  3.  2.]]\n",
      "2.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def levenshtein(seq1, seq2):  \n",
    "    size_x = len(seq1) + 1\n",
    "    size_y = len(seq2) + 1\n",
    "    matrix = np.zeros ((size_x, size_y))\n",
    "    for x in xrange(size_x):\n",
    "        matrix [x, 0] = x\n",
    "    for y in xrange(size_y):\n",
    "        matrix [0, y] = y\n",
    "\n",
    "    for x in xrange(1, size_x):\n",
    "        for y in xrange(1, size_y):\n",
    "            if seq1[x-1] == seq2[y-1]:\n",
    "                matrix [x,y] = min(\n",
    "                    matrix[x-1, y] + 1,\n",
    "                    matrix[x-1, y-1],\n",
    "                    matrix[x, y-1] + 1\n",
    "                )\n",
    "            else:\n",
    "                matrix [x,y] = min(\n",
    "                    matrix[x-1,y] + 1,\n",
    "                    matrix[x-1,y-1] + 1,\n",
    "                    matrix[x,y-1] + 1\n",
    "                )\n",
    "    print (matrix)\n",
    "    return (matrix[size_x - 1, size_y - 1])\n",
    "\n",
    "if __name__=='__main__':\n",
    "    print levenshtein('test', 'toast')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "entzückend Chaos,\n",
      "kontrastierend kalter Landschaft,\n",
      "unersetzliche Phantasie.\n"
     ]
    }
   ],
   "source": [
    "# Haiku generator\n",
    "from random import randint\n",
    "\n",
    "wordList1 = [\"berauschend\", \"erstaunlich\", \"farbenfroh\", \"entzückend\", \"zarteste\"]\n",
    "wordList2 = [\"Visionen\", \"Entfernung\", \"Gewissen\", \"Prozess\", \"Chaos\"]\n",
    "wordList3 = [\"abergläubisch\", \"kontrastierend\", \"anmutig\", \"einladend\", \"widersprüchlich\", \"überwältigend\"]\n",
    "wordList4 = [\"wahrer\", \"dunkler\", \"kalter\", \"warmer\", \"heller\"]\n",
    "wordList5 = [\"Landschaft\", \"Jahreszeit\", \"Farben\", \"Licht\", \"Frühling\", \"Winter\", \"Sommer\", \"Herbst\"]\n",
    "wordList6 = [\"unbestreitbare\", \"schöne\", \"unersetzliche\", \"unglaubliche\", \"unwiderrufliche\"]\n",
    "wordList7 = [\"Inspiration\", \"Phantasie\", \"Weisheit\", \"Gedanken\"]\n",
    "\n",
    "wordIndex1=randint(0, len(wordList1)-1)\n",
    "wordIndex2=randint(0, len(wordList2)-1)\n",
    "wordIndex3=randint(0, len(wordList3)-1)\n",
    "wordIndex4=randint(0, len(wordList4)-1)\n",
    "wordIndex5=randint(0, len(wordList5)-1)\n",
    "wordIndex6=randint(0, len(wordList6)-1)\n",
    "wordIndex7=randint(0, len(wordList7)-1)\n",
    "\n",
    "haiku = wordList1[wordIndex1] + \" \" + wordList2[wordIndex2] + \",\\n\" \n",
    "haiku = haiku + wordList3[wordIndex3] + \" \" + wordList4[wordIndex4] + \" \" + wordList5[wordIndex5]  + \",\\n\"\n",
    "haiku = haiku + wordList6[wordIndex6] + \" \" + wordList7[wordIndex7] + \".\"\n",
    "\n",
    "print(haiku)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, 'a', 1), (2, 'b', 2), (3, 'c', 3)]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zip([1,2,3], ['a', 'b', 'c'], [1,2,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(2, 2), (7, 1)]\n",
      "[(2, 3), (3, 1), (5, 1)]\n",
      "[(2, 2), (3, 3)]\n",
      "[(2, 1), (3, 1), (7, 1)]\n",
      "[(2, 4), (3, 1)]\n",
      "[(2, 2), (3, 2), (5, 1)]\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "# semiprimes\n",
    "import math\n",
    "\n",
    "def sieveEra(n):\n",
    "    alst = [1] * (n+1)\n",
    "    ilim = int(math.sqrt(n))+1\n",
    "    for i in range(2, ilim):\n",
    "        if alst[i] == 1:\n",
    "            j = i*i\n",
    "            while j <= n:\n",
    "                alst[j] = 0\n",
    "                j += i\n",
    "    return alst\n",
    "\n",
    "def primes(n): # returns a list of primes up to n\n",
    "    alst = sieveEra(n)\n",
    "    res = []\n",
    "    for i in range(2,n):\n",
    "        if alst[i] > 0:\n",
    "            res.append(i * alst[i])\n",
    "    return res\n",
    "\n",
    "def factors(n): # only true factors\n",
    "    res = []\n",
    "    lp = primes(int(n/2))\n",
    "    for p in lp:\n",
    "        if n % p == 0:\n",
    "            elim = int(math.log(n)/math.log(p))\n",
    "            for e in range(1, elim+2):\n",
    "                if n % (p**e) != 0:\n",
    "                    res.append((p, e-1))\n",
    "                    break\n",
    "    return res\n",
    "\n",
    "def issemip(n):\n",
    "    lf = factors(n)\n",
    "    for e in lf:\n",
    "        if e[1] > 1:\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "if __name__=='__main__':\n",
    "    #print sieveEra(10)\n",
    "    print factors(28)\n",
    "    print factors(120)\n",
    "    print factors(108)\n",
    "    print factors(42)\n",
    "    print factors(48)\n",
    "    print factors(180)\n",
    "    print issemip(46)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2**2-1 = 3, with factors:\n",
      "3 => 0.00s\n",
      "2**3-1 = 7, with factors:\n",
      "7 => 0.00s\n",
      "2**5-1 = 31, with factors:\n",
      "31 => 0.00s\n",
      "2**7-1 = 127, with factors:\n",
      "127 => 0.00s\n",
      "2**11-1 = 2047, with factors:\n",
      "23 89 => 0.00s\n",
      "2**13-1 = 8191, with factors:\n",
      "8191 => 0.00s\n",
      "2**17-1 = 131071, with factors:\n",
      "131071 => 0.00s\n",
      "2**19-1 = 524287, with factors:\n",
      "524287 => 0.00s\n",
      "2**23-1 = 8388607, with factors:\n",
      "47 178481 => 0.01s\n",
      "2**29-1 = 536870911, with factors:\n",
      "233 1103 2089 => 0.01s\n",
      "2**31-1 = 2147483647, with factors:\n",
      "2147483647 => 0.01s\n",
      "2**37-1 = 137438953471, with factors:\n",
      "223 616318177 => 0.01s\n",
      "2**41-1 = 2199023255551, with factors:\n",
      "13367 164511353 => 0.01s\n",
      "2**43-1 = 8796093022207, with factors:\n",
      "431 9719 2099863 => 0.01s\n",
      "2**47-1 = 140737488355327, with factors:\n",
      "2351 4513 13264529 => 0.01s\n",
      "2**53-1 = 9007199254740991, with factors:\n",
      "6361 69431 20394401 => 0.02s\n",
      "2**59-1 = 576460752303423487, with factors:\n",
      "179951 3203431780337 => 0.39s\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    " \n",
    "import sys\n",
    "from itertools import islice, cycle, count\n",
    " \n",
    "try:\n",
    "    from itertools import compress\n",
    "except ImportError:\n",
    "    def compress(data, selectors):\n",
    "        \"\"\"compress('ABCDEF', [1,0,1,0,1,1]) --> A C E F\"\"\"\n",
    "        return (d for d, s in zip(data, selectors) if s)\n",
    " \n",
    " \n",
    "def is_prime(n):\n",
    "    return list(zip((True, False), decompose(n)))[-1][0]\n",
    " \n",
    "class IsPrimeCached(dict):\n",
    "    def __missing__(self, n):\n",
    "        r = is_prime(n)\n",
    "        self[n] = r\n",
    "        return r\n",
    " \n",
    "is_prime_cached = IsPrimeCached()\n",
    " \n",
    "def croft():\n",
    "    \"\"\"Yield prime integers using the Croft Spiral sieve.\n",
    " \n",
    "    This is a variant of wheel factorisation modulo 30.\n",
    "    \"\"\"\n",
    "    # Copied from:\n",
    "    #   https://code.google.com/p/pyprimes/source/browse/src/pyprimes.py\n",
    "    # Implementation is based on erat3 from here:\n",
    "    #   http://stackoverflow.com/q/2211990\n",
    "    # and this website:\n",
    "    #   http://www.primesdemystified.com/\n",
    "    # Memory usage increases roughly linearly with the number of primes seen.\n",
    "    # dict ``roots`` stores an entry x:p for every prime p.\n",
    "    for p in (2, 3, 5):\n",
    "        yield p\n",
    "    roots = {9: 3, 25: 5}  # Map d**2 -> d.\n",
    "    primeroots = frozenset((1, 7, 11, 13, 17, 19, 23, 29))\n",
    "    selectors = (1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0)\n",
    "    for q in compress(\n",
    "            # Iterate over prime candidates 7, 9, 11, 13, ...\n",
    "            islice(count(7), 0, None, 2),\n",
    "            # Mask out those that can't possibly be prime.\n",
    "            cycle(selectors)\n",
    "            ):\n",
    "        # Using dict membership testing instead of pop gives a\n",
    "        # 5-10% speedup over the first three million primes.\n",
    "        if q in roots:\n",
    "            p = roots[q]\n",
    "            del roots[q]\n",
    "            x = q + 2*p\n",
    "            while x in roots or (x % 30) not in primeroots:\n",
    "                x += 2*p\n",
    "            roots[x] = p\n",
    "        else:\n",
    "            roots[q*q] = q\n",
    "            yield q\n",
    "primes = croft\n",
    " \n",
    "def decompose(n):\n",
    "    for p in primes():\n",
    "        if p*p > n: break\n",
    "        while n % p == 0:\n",
    "            yield p\n",
    "            n //=p\n",
    "    if n > 1:\n",
    "        yield n\n",
    " \n",
    " \n",
    "if __name__ == '__main__':\n",
    "    # Example: calculate factors of Mersenne numbers to M59 #\n",
    " \n",
    "    import time\n",
    " \n",
    "    for m in primes():\n",
    "        p = 2 ** m - 1\n",
    "        print( \"2**{0:d}-1 = {1:d}, with factors:\".format(m, p) )\n",
    "        start = time.time()\n",
    "        for factor in decompose(p):\n",
    "            print(factor, end=' ')\n",
    "            sys.stdout.flush()\n",
    " \n",
    "        print( \"=> {0:.2f}s\".format( time.time()-start ) )\n",
    "        if m >= 59:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, 1, 2]\n",
      "[3, 0, 1, 2, 3]\n"
     ]
    }
   ],
   "source": [
    "# exploding dots\n",
    "\n",
    "def resolve(n, nlim, nexp, nlft):\n",
    "    res = [n]\n",
    "    i = 0\n",
    "    while True:\n",
    "        while res[i] >= nlim:\n",
    "            res[i] -= (nexp + nlft)\n",
    "            if i == len(res)-1:\n",
    "                res.append(nlft)\n",
    "            else:\n",
    "                res[i+1] += nlft\n",
    "        i += 1\n",
    "        if res[i] < nlim:\n",
    "            break\n",
    "    return res\n",
    "\n",
    "if __name__=='__main__':\n",
    "    print resolve(8, 3, 1, 2)\n",
    "    print resolve(19, 4, 1, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pygame.midi\n",
    "import time\n",
    "\n",
    "pygame.midi.init()\n",
    "player = pygame.midi.Output(0)\n",
    "player.set_instrument(0)\n",
    "player.note_on(64, 127) # 74 is the midi note number https://newt.phys.unsw.edu.au/jw/notes.html\n",
    "time.sleep(1)\n",
    "player.note_off(64, 127)\n",
    "del player\n",
    "pygame.midi.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tune test\n",
    "import pygame.midi\n",
    "import time\n",
    "\n",
    "def playnote(pl, n, lgth):\n",
    "    pl.note_on(n, 127) # midi note number https://newt.phys.unsw.edu.au/jw/notes.html and loudness\n",
    "    time.sleep(lgth)\n",
    "    pl.note_off(n, 127)\n",
    "    return 0\n",
    "\n",
    "if __name__=='__main__':\n",
    "    pygame.midi.init()\n",
    "    pl = pygame.midi.Output(0)\n",
    "    pl.set_instrument(0)\n",
    "    tunen = [45, 64, 64, 45, 57, 33]\n",
    "    tunel = [0.8, 0.5, 0.5, 0.8, 0.6, 1]\n",
    "    for i in range(len(tunen)):\n",
    "        playnote(pl, tunen[i], tunel[i])\n",
    "    del pl\n",
    "    pygame.midi.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8192\n",
      "8192\n",
      "8192\n"
     ]
    }
   ],
   "source": [
    "# binom sums\n",
    "import math\n",
    "\n",
    "def binom(a,b):\n",
    "    if a==0 or a <= b:\n",
    "        return 1\n",
    "    return math.factorial(a) / math.factorial(b) / math.factorial(a-b)\n",
    "\n",
    "def aa(n):\n",
    "    res = 0\n",
    "    for k in range(0,n+1,2):\n",
    "        res += binom(n, k)\n",
    "    return res\n",
    "\n",
    "def bb(n):\n",
    "    res = 0\n",
    "    for k in range(1,n+1,2):\n",
    "        res += binom(n, k)\n",
    "    return res\n",
    "\n",
    "def bb2(n):\n",
    "    res = 0\n",
    "    for k in range(0,n+1,2):\n",
    "        res += binom(n, k) * (n+1) / (k+1)\n",
    "    return res/2\n",
    "\n",
    "if __name__=='__main__':\n",
    "    n = 14\n",
    "    print aa(n)\n",
    "    print bb(n)\n",
    "    print bb2(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dictionary(7 unique tokens: [u'meow', u'dog', u'cat', u'say', u'computer']...)\n"
     ]
    }
   ],
   "source": [
    "from gensim.corpora import Dictionary\n",
    "\n",
    "texts = [['human', 'interface', 'computer']]\n",
    "dct = Dictionary(texts)  # initialize a Dictionary\n",
    "dct.add_documents([[\"cat\", \"say\", \"meow\"], [\"dog\"]])  # add more document (extend the vocabulary)\n",
    "# Convert document into the bag-of-words (BoW) format = list of (token_id, token_count) tuples\n",
    "dct.doc2bow([\"dog\", \"computer\", \"non_existent_word\"], return_missing=True)\n",
    "dct[2] # dct.id2token(2)\n",
    "print dct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17 1 20\n",
      "340\n",
      "21 1 16\n",
      "336\n"
     ]
    }
   ],
   "source": [
    "# integer equations\n",
    "\n",
    "def e1(x,y,z):\n",
    "    return x*y+x*z-357\n",
    "\n",
    "def e2(x,y,z):\n",
    "    return x*y+y*z-37\n",
    "\n",
    "if __name__=='__main__':\n",
    "    for x in range(1,60):\n",
    "        for y in range(1,60):\n",
    "            for z in range(1,60):\n",
    "                if e1(x,y,z) == 0 and e2(x,y,z) == 0:\n",
    "                    print '%d %d %d' %  (x,y,z)\n",
    "                    print x*y*z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.182\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "# Googol\n",
    "import random\n",
    "\n",
    "def genslips(n):\n",
    "    res = []\n",
    "    for i in range(n):\n",
    "        res.append(random.uniform(0.00001, 100000000.))\n",
    "    return res\n",
    "\n",
    "def choosen(n, slips):\n",
    "    ms = max(slips)\n",
    "    ns = len(slips)\n",
    "    for k in range(n):\n",
    "        if slips[random.randrange(ns)] >= ms:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "def strat0(slips):\n",
    "    ms = max(slips)\n",
    "    avchoice = 0.\n",
    "    for k in range(len(slips)-1):\n",
    "        thischoice = slips.pop(random.randrange(len(slips)))\n",
    "        if k > 0:\n",
    "            if thischoice > avchoice:\n",
    "                if thischoice == ms:\n",
    "                    return (k, True)\n",
    "                else:\n",
    "                    return (k, False)\n",
    "        avchoice += thischoice/(k+1.)\n",
    "    return (len(slips)-1, False)\n",
    "\n",
    "def rej(n, p):\n",
    "    res = 0.\n",
    "    for k in range(p,n-1):\n",
    "        res += 1./k\n",
    "    return res * p / n\n",
    "\n",
    "def nrej(n):\n",
    "    lastp = 0.\n",
    "    for k in range(2,n):\n",
    "        thisp = rej(n,k)\n",
    "        if thisp < lastp:\n",
    "            return k\n",
    "        lastp = thisp\n",
    "    return n\n",
    "\n",
    "if __name__=='__main__':\n",
    "    n = 10\n",
    "    ns = genslips(n)\n",
    "    res = [0] * n\n",
    "    nruns = 1000\n",
    "    nsucc = 0\n",
    "    for i in range(nruns):\n",
    "        #for k in range(1,n):\n",
    "            #if choosen(k, ns):\n",
    "                #res[k] += 1\n",
    "        ns = genslips(n)\n",
    "        if strat0(ns)[1]:\n",
    "            nsucc += 1\n",
    "    #print res\n",
    "    print float(nsucc) / nruns\n",
    "    print nrej(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "125\n"
     ]
    }
   ],
   "source": [
    "# Ackermann function\n",
    "\n",
    "def ackermann(m,n):\n",
    "    if m == 0:\n",
    "        return n+1\n",
    "    if n == 0:\n",
    "        return ackermann(m-1, 1)\n",
    "    return ackermann(m-1, ackermann(m, n-1))\n",
    "\n",
    "if __name__=='__main__':\n",
    "    print ackermann(3, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{}\n",
      "{ABC}\n",
      "{ABC and DEF}\n",
      "{ABC, DEF, G and H}\n"
     ]
    }
   ],
   "source": [
    "# Comma quibbling\n",
    "\n",
    "def quibbled(sl):\n",
    "    nsl = len(sl)\n",
    "    if nsl == 0:\n",
    "        return '{}'\n",
    "    res = ''.join(sl[0])\n",
    "    for i in range(1, nsl):\n",
    "        if i == nsl-1:\n",
    "            res += ' and '\n",
    "        else:\n",
    "            res += ', '\n",
    "        res += sl[i]\n",
    "    return '{' + res + '}'\n",
    "    \n",
    "if __name__=='__main__':\n",
    "    print quibbled([])\n",
    "    print quibbled([\"ABC\"])\n",
    "    print quibbled([\"ABC\", \"DEF\"])\n",
    "    print quibbled([\"ABC\", \"DEF\", \"G\", \"H\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.16563713361\n",
      "5.85667000806\n"
     ]
    }
   ],
   "source": [
    "# continued fractions\n",
    "\n",
    "def contfc(n):\n",
    "    if n == 200:\n",
    "        return 1.\n",
    "    return 1. + 1. / (n + contfc(n+1))\n",
    "\n",
    "def contfd(n):\n",
    "    if n == 200:\n",
    "        return 1.\n",
    "    return n + (n + 1.) / (n + 2. + contfc(n+1))\n",
    "\n",
    "if __name__=='__main__':\n",
    "    print contfc(1)*5.\n",
    "    print contfd(1)*4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1. -1. -1. -1. -1.]\n",
      " [ 1.  1.  3.  1.  1.]]\n",
      "[1 0]\n",
      "[[ 0.10225897  0.89774103]\n",
      " [ 0.97116002  0.02883998]]\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Multi-layer Perceptron is sensitive to feature scaling, so it is highly recommended to scale your data.\n",
    "# For example, scale each attribute on the input vector X to [0, 1] or [-1, +1]. e.g. scaler = StandardScaler()\n",
    "# Finding a reasonable regularization parameter  is best done using GridSearchCV,\n",
    "# usually in the range 10.0 ** -np.arange(1, 7)\n",
    "# Empirically, we observed that L-BFGS converges faster and with better solutions on small datasets.\n",
    "# For relatively large datasets, however, Adam is very robust.\n",
    "\n",
    "if __name__=='__main__':\n",
    "    # X : array-like or sparse matrix, shape (n_samples, n_features)\n",
    "    # y : array-like, shape (n_samples,) or (n_samples, n_outputs)\n",
    "    X = [[0., 0., 0., 0., 0.], [1., 1., 1., 1., 1.]]\n",
    "    y = [0, 1]\n",
    "    \n",
    "    X_train = [[0., 0., 0., 0., 0.], [1., 1., 1., 1., 1.]]\n",
    "    X_test = [[0., 0., 0., 0., 0.], [1., 1., 2., 1., 1.]]\n",
    "    scaler = StandardScaler() \n",
    "    scaler.fit(X_train)\n",
    "    X_train = scaler.transform(X_train)\n",
    "    X_test = scaler.transform(X_test) \n",
    "    print X_test\n",
    "    \n",
    "    clf = MLPClassifier(solver='lbfgs', alpha=1e-5, hidden_layer_sizes=(5, 2), random_state=1)\n",
    "    clf.fit(X, y)\n",
    "    print clf.predict([[1., 1., 1., 0., 0.], [0., 0., 0., 0., 1.]])\n",
    "    print clf.predict_proba([[1., 1., 1., 0., 0.], [0., 0., 0., 0., 1.]])\n",
    "    print clf.score(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "most representative part of doc 0: index 1 : part b\n"
     ]
    }
   ],
   "source": [
    "# small LDA example for demo purposes\n",
    "import random\n",
    "import math\n",
    "import time\n",
    "\n",
    "def poissonrn(lda): # generate a poisson random number\n",
    "    l = math.exp(-lda)\n",
    "    k = 1.\n",
    "    p = random.random()\n",
    "    while p > l:\n",
    "        k += 1.\n",
    "        p *= random.random()\n",
    "    return (k-1.)\n",
    "\n",
    "def dirichlet(params): # sample dirichlet distribution\n",
    "    sample = [random.gammavariate(a,1) for a in params]\n",
    "    sample = [v/sum(sample) for v in sample]\n",
    "    return sample\n",
    "\n",
    "def partsct(doc): # find all parts of a document and count its respective occurance\n",
    "    chklst = []\n",
    "    ctlst = []\n",
    "    for e in doc:\n",
    "        if not e in chklst:\n",
    "            chklst.append(e)\n",
    "            ctlst.append(1)\n",
    "        else:\n",
    "            ctlst[chklst.index(e)] += 1\n",
    "    return (chklst, ctlst)\n",
    "\n",
    "def doc_parts_tbl(docs): # build a document-parts table\n",
    "    ptslst = []\n",
    "    for d in docs:\n",
    "        ptslst.append(partsct(d)) \n",
    "    return ptslst\n",
    "\n",
    "def all_parts(dbt): # a list of all parts in all docs, uniquely, from doc parts table\n",
    "    apts = []\n",
    "    for d in dbt:\n",
    "        for de in d[0]:\n",
    "            if not de in apts:\n",
    "                apts.append(de)\n",
    "    return apts\n",
    "\n",
    "def parts_per_doc(lda): # pick how many parts you want per each composite (doc) - from Poisson distribution\n",
    "    return poissonrn(lda)\n",
    "\n",
    "def parts_topics(parts, topics, beta): # build the parts-topics table: for each column draw from Dirichlet distr.(beta)\n",
    "    res = []\n",
    "    betalst = []\n",
    "    for p in parts:\n",
    "        betalst.append(beta)\n",
    "    for t in topics:\n",
    "        res.append(dirichlet(betalst))\n",
    "    return res\n",
    "\n",
    "def comp_topics(docs, topics, alpha): # build the composites(docs)-topics table: for each row draw from Dirichlet distr.(alpha)\n",
    "    res = []\n",
    "    alphalst = []\n",
    "    for t in topics:\n",
    "        alphalst.append(alpha)\n",
    "    for d in docs:\n",
    "        res.append(dirichlet(alphalst))\n",
    "    return res\n",
    "\n",
    "def smpl_topbydoc(ndoc, doctop): # sample topic by document\n",
    "    maxtop = 0.\n",
    "    i = 0\n",
    "    imax = 0\n",
    "    for p in doctop[ndoc]:\n",
    "        if p > maxtop:\n",
    "            maxtop = p\n",
    "            imax = i\n",
    "        i += 1\n",
    "    return imax\n",
    "\n",
    "def smpl_partsbytop(ntop, parttop): # sample parts by topic\n",
    "    maxprt = 0.\n",
    "    i = 0\n",
    "    imax = 0\n",
    "    for p in parttop[ntop]:\n",
    "        if p > maxprt:\n",
    "            maxprt = p\n",
    "            imax = i\n",
    "        i += 1\n",
    "    return imax\n",
    "\n",
    "if __name__=='__main__':\n",
    "    docs = []\n",
    "    docs.append('aaaaa')\n",
    "    docs.append('bbbbb')\n",
    "    docs.append('ccccc')\n",
    "    docs.append('aaaaabbbbbccccc')\n",
    "    #print docs\n",
    "    dbt = doc_parts_tbl(docs) # document and parts table\n",
    "    #print dbt\n",
    "    random.seed(time.clock())\n",
    "    ntop = 3 # number of topics\n",
    "    alpha = 0.2\n",
    "    beta = 0.5\n",
    "    #print dirichlet([beta, beta])\n",
    "    apts = all_parts(dbt)\n",
    "    parttop = parts_topics(apts, [0, 1, 2], beta)\n",
    "    doctop = comp_topics(apts, docs, alpha)\n",
    "    maxtop = smpl_topbydoc(0, doctop)\n",
    "    npt = smpl_partsbytop(maxtop, parttop)\n",
    "    print 'most representative part of doc 0: index %d : part %s' % (npt, apts[npt])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\n",
      "[[ 0.19547634  0.19551008  0.20323978  0.20577707  0.19999673]]\n",
      "0.2\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "\n",
    "def rnd_shelf(nsmpls, nspot, nprod, config):\n",
    "    X = []\n",
    "    y = []\n",
    "    for k in range(nsmpls):\n",
    "        xs = []\n",
    "        for i in range(nspot):\n",
    "            if config == 0:\n",
    "                if i < nspot/2:\n",
    "                    xs.append(1.)\n",
    "                else:\n",
    "                    xs.append(2.)\n",
    "        X.append(xs)\n",
    "        y.append(k % nsmpls)\n",
    "    return (X, y)\n",
    "\n",
    "# Multi-layer Perceptron is sensitive to feature scaling, so it is highly recommended to scale your data.\n",
    "# For example, scale each attribute on the input vector X to [0, 1] or [-1, +1]. e.g. scaler = StandardScaler()\n",
    "# Finding a reasonable regularization parameter  is best done using GridSearchCV,\n",
    "# usually in the range 10.0 ** -np.arange(1, 7)\n",
    "# Empirically, we observed that L-BFGS converges faster and with better solutions on small datasets.\n",
    "# For relatively large datasets, however, Adam is very robust.\n",
    "\n",
    "if __name__=='__main__':\n",
    "    # X : array-like or sparse matrix, shape (n_samples, n_features)\n",
    "    # y : array-like, shape (n_samples,) or (n_samples, n_outputs)\n",
    "    #X = [[0., 0., 0., 0., 0.], [1., 1., 1., 1., 1.], [0., 1., 0., 1., 0.]]\n",
    "    #X = np.random.rand(3,340)\n",
    "    #y = [0, 1, 0]\n",
    "    X, y = rnd_shelf(5, 340, 2, 0)\n",
    "    \n",
    "    clf = MLPClassifier(solver='lbfgs', alpha=1e-5, hidden_layer_sizes=(5, 2), random_state=1)\n",
    "    clf.fit(X, y)\n",
    "    print clf.predict(np.random.rand(1,340))\n",
    "    print clf.predict_proba(np.random.rand(1,340))\n",
    "    print clf.score(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
