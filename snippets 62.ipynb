{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c96eef5e-5e80-404c-844a-7e71228a176d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://huggingface.co/mistralai/Mixtral-8x7B-Instruct-v0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ba176aec-b335-4276-aaae-41fcb604d120",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "def gcd(u, v):\n",
    "    if v != 0:\n",
    "        (u, v) = (v, u % v)\n",
    "    return abs(u)\n",
    "\n",
    "gcd(144, 12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "969101c4-bd6b-4194-b149-8afb96e0ad32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1],\n",
       "       [0, 0]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# demo NN\n",
    "import numpy as np\n",
    "\n",
    "x0 = np.array([[1], [0]])\n",
    "w0 = np.array([[0, 1]])\n",
    "\n",
    "y = x0 * w0\n",
    "\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9e0715f8-658a-49fb-92e4-7fa109fdc688",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "\n",
    "x=y=0.1\n",
    "fig1 = plt.figure()\n",
    "ax1 = fig1.add_subplot(111, aspect='equal')\n",
    "patch= ax1.add_patch(patches.Rectangle((x, y), 0.5, 0.5, alpha=0.1,facecolor='red',label='Label'))\n",
    "\n",
    "centerx = x + 0.5/2 - 0.05\n",
    "centery = y + 0.5/2\n",
    "\n",
    "plt.axis('off')\n",
    "plt.text(centerx, centery,'test')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb8fa9c2-93c6-4d6f-9acc-abcc239798bc",
   "metadata": {},
   "source": [
    "## Simple NN Demo\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "60e07701-e539-4768-9175-7db3d10fa856",
   "metadata": {},
   "outputs": [],
   "source": [
    "# weight --- w1 ---- h1\n",
    "#        \\ /-----w2-/  \\ w5 - output:\n",
    "#        / \\-----w3-\\  / w6 - gender\n",
    "# height --- w4 ---- h2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "181e862f-c065-4f80-93ad-5c497650b03d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 loss: 0.147\n",
      "Epoch 20 loss: 0.047\n",
      "Epoch 40 loss: 0.028\n",
      "Epoch 60 loss: 0.020\n",
      "Epoch 80 loss: 0.015\n",
      "Epoch 100 loss: 0.012\n",
      "Epoch 120 loss: 0.010\n",
      "Epoch 140 loss: 0.008\n",
      "Epoch 160 loss: 0.007\n",
      "Epoch 180 loss: 0.006\n",
      "execution time: 13.095617294311523 ms\n"
     ]
    }
   ],
   "source": [
    "# https://victorzhou.com/blog/intro-to-neural-networks/\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "def sigmoid(x):\n",
    "  # Sigmoid activation function: f(x) = 1 / (1 + e^(-x))\n",
    "  return 1 / (1 + np.exp(-x))\n",
    "\n",
    "def deriv_sigmoid(x):\n",
    "  # Derivative of sigmoid: f'(x) = f(x) * (1 - f(x))\n",
    "  fx = sigmoid(x)\n",
    "  return fx * (1 - fx)\n",
    "\n",
    "def mse_loss(y_true, y_pred):\n",
    "  # y_true and y_pred are numpy arrays of the same length.\n",
    "  return ((y_true - y_pred) ** 2).mean()\n",
    "\n",
    "class OurNeuralNetwork:\n",
    "  '''\n",
    "  A neural network with:\n",
    "    - 2 inputs\n",
    "    - a hidden layer with 2 neurons (h1, h2)\n",
    "    - an output layer with 1 neuron (o1)\n",
    "\n",
    "  *** DISCLAIMER ***:\n",
    "  The code below is intended to be simple and educational, NOT optimal.\n",
    "  Real neural net code looks nothing like this. DO NOT use this code.\n",
    "  Instead, read/run it to understand how this specific network works.\n",
    "  '''\n",
    "  def __init__(self):\n",
    "    # Weights\n",
    "    self.w1 = np.random.normal()\n",
    "    self.w2 = np.random.normal()\n",
    "    self.w3 = np.random.normal()\n",
    "    self.w4 = np.random.normal()\n",
    "    self.w5 = np.random.normal()\n",
    "    self.w6 = np.random.normal()\n",
    "\n",
    "    # Biases\n",
    "    self.b1 = np.random.normal()\n",
    "    self.b2 = np.random.normal()\n",
    "    self.b3 = np.random.normal()\n",
    "\n",
    "  def feedforward(self, x):\n",
    "    # x is a numpy array with 2 elements.\n",
    "    h1 = sigmoid(self.w1 * x[0] + self.w2 * x[1] + self.b1)\n",
    "    h2 = sigmoid(self.w3 * x[0] + self.w4 * x[1] + self.b2)\n",
    "    o1 = sigmoid(self.w5 * h1 + self.w6 * h2 + self.b3)\n",
    "    return o1\n",
    "\n",
    "  def train(self, data, all_y_trues):\n",
    "    '''\n",
    "    - data is a (n x 2) numpy array, n = # of samples in the dataset.\n",
    "    - all_y_trues is a numpy array with n elements.\n",
    "      Elements in all_y_trues correspond to those in data.\n",
    "    '''\n",
    "    learn_rate = 0.15\n",
    "    epochs = 200 # number of times to loop through the entire dataset\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "      for x, y_true in zip(data, all_y_trues):\n",
    "        # --- Do a feedforward (we'll need these values later)\n",
    "        sum_h1 = self.w1 * x[0] + self.w2 * x[1] + self.b1\n",
    "        h1 = sigmoid(sum_h1)\n",
    "\n",
    "        sum_h2 = self.w3 * x[0] + self.w4 * x[1] + self.b2\n",
    "        h2 = sigmoid(sum_h2)\n",
    "\n",
    "        sum_o1 = self.w5 * h1 + self.w6 * h2 + self.b3\n",
    "        o1 = sigmoid(sum_o1)\n",
    "        y_pred = o1\n",
    "\n",
    "        # --- Calculate partial derivatives.\n",
    "        # --- Naming: d_L_d_w1 represents \"partial L / partial w1\"\n",
    "        d_L_d_ypred = -2 * (y_true - y_pred)\n",
    "\n",
    "        # Neuron o1\n",
    "        d_ypred_d_w5 = h1 * deriv_sigmoid(sum_o1)\n",
    "        d_ypred_d_w6 = h2 * deriv_sigmoid(sum_o1)\n",
    "        d_ypred_d_b3 = deriv_sigmoid(sum_o1)\n",
    "\n",
    "        d_ypred_d_h1 = self.w5 * deriv_sigmoid(sum_o1)\n",
    "        d_ypred_d_h2 = self.w6 * deriv_sigmoid(sum_o1)\n",
    "\n",
    "        # Neuron h1\n",
    "        d_h1_d_w1 = x[0] * deriv_sigmoid(sum_h1)\n",
    "        d_h1_d_w2 = x[1] * deriv_sigmoid(sum_h1)\n",
    "        d_h1_d_b1 = deriv_sigmoid(sum_h1)\n",
    "\n",
    "        # Neuron h2\n",
    "        d_h2_d_w3 = x[0] * deriv_sigmoid(sum_h2)\n",
    "        d_h2_d_w4 = x[1] * deriv_sigmoid(sum_h2)\n",
    "        d_h2_d_b2 = deriv_sigmoid(sum_h2)\n",
    "\n",
    "        # --- Update weights and biases\n",
    "        # Neuron h1\n",
    "        self.w1 -= learn_rate * d_L_d_ypred * d_ypred_d_h1 * d_h1_d_w1\n",
    "        self.w2 -= learn_rate * d_L_d_ypred * d_ypred_d_h1 * d_h1_d_w2\n",
    "        self.b1 -= learn_rate * d_L_d_ypred * d_ypred_d_h1 * d_h1_d_b1\n",
    "\n",
    "        # Neuron h2\n",
    "        self.w3 -= learn_rate * d_L_d_ypred * d_ypred_d_h2 * d_h2_d_w3\n",
    "        self.w4 -= learn_rate * d_L_d_ypred * d_ypred_d_h2 * d_h2_d_w4\n",
    "        self.b2 -= learn_rate * d_L_d_ypred * d_ypred_d_h2 * d_h2_d_b2\n",
    "\n",
    "        # Neuron o1\n",
    "        self.w5 -= learn_rate * d_L_d_ypred * d_ypred_d_w5\n",
    "        self.w6 -= learn_rate * d_L_d_ypred * d_ypred_d_w6\n",
    "        self.b3 -= learn_rate * d_L_d_ypred * d_ypred_d_b3\n",
    "\n",
    "      # --- Calculate total loss at the end of each epoch\n",
    "      if epoch % 20 == 0:\n",
    "        y_preds = np.apply_along_axis(self.feedforward, 1, data)\n",
    "        loss = mse_loss(all_y_trues, y_preds)\n",
    "        print(\"Epoch %d loss: %.3f\" % (epoch, loss))\n",
    "\n",
    "# training dataset\n",
    "data = np.array([\n",
    "  [-2, -1],  # Alice\n",
    "  [25, 6],   # Bob\n",
    "  [17, 4],   # Charlie\n",
    "  [-15, -6], # Diana\n",
    "])\n",
    "\n",
    "all_y_trues = np.array([\n",
    "  1, # Alice\n",
    "  0, # Bob\n",
    "  0, # Charlie\n",
    "  1, # Diana\n",
    "])\n",
    "\n",
    "start = time.time()\n",
    "# Train our neural network!\n",
    "network = OurNeuralNetwork()\n",
    "network.train(data, all_y_trues)\n",
    "end = time.time()\n",
    "print(f\"execution time: {(end-start) * 10**3} ms\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "d05a6ad8-05cd-4625-a5d6-28eecf3684e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation loss: 0.0056283013651685886\n"
     ]
    }
   ],
   "source": [
    "# validation\n",
    "# test data\n",
    "testdata = np.array([\n",
    "  [-3, -1],  # Rachel\n",
    "  [21, 5],   # John\n",
    "])\n",
    "\n",
    "test_truth = np.array([\n",
    "  1, # Rachel\n",
    "  0, # John\n",
    "])\n",
    "\n",
    "test_preds = np.apply_along_axis(network.feedforward, 1, testdata)\n",
    "loss = mse_loss(test_truth, test_preds)\n",
    "print(f\"validation loss: {loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "96c31a97-ad99-4b93-968f-5d3cb258abb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Emily: 0.936\n",
      "Frank: 0.075\n"
     ]
    }
   ],
   "source": [
    "# Make some predictions\n",
    "emily = np.array([-7, -3]) # 128 pounds, 63 inches\n",
    "frank = np.array([20, 2])  # 155 pounds, 68 inches\n",
    "print(\"Emily: %.3f\" % network.feedforward(emily)) # 0.951 - F\n",
    "print(\"Frank: %.3f\" % network.feedforward(frank)) # 0.039 - M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f003e843-e16d-4645-844e-6e8eb4ecf241",
   "metadata": {},
   "outputs": [],
   "source": [
    "# how to prevent overfitting: https://programming-review.com/machine-learning/overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "57a16311-5b94-4475-a2ed-0c56713d840f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 loss: 0.293\n",
      "Epoch 20 loss: 0.161\n",
      "Epoch 40 loss: 0.082\n",
      "Epoch 60 loss: 0.048\n",
      "Epoch 80 loss: 0.033\n",
      "Epoch 100 loss: 0.024\n",
      "Epoch 120 loss: 0.019\n",
      "Epoch 140 loss: 0.015\n",
      "Epoch 160 loss: 0.013\n",
      "Epoch 180 loss: 0.011\n",
      "execution time: 34.03043746948242 ms\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "\n",
    "def sigmoid(x):\n",
    "  # Sigmoid activation function: f(x) = 1 / (1 + e^(-x))\n",
    "  return 1 / (1 + np.exp(-x))\n",
    "\n",
    "def deriv_sigmoid(x):\n",
    "  # Derivative of sigmoid: f'(x) = f(x) * (1 - f(x))\n",
    "  fx = sigmoid(x)\n",
    "  return fx * (1 - fx)\n",
    "\n",
    "def mse_loss(y_true, y_pred):\n",
    "  # y_true and y_pred are numpy arrays of the same length.\n",
    "  return ((y_true - y_pred[:,0,0]) ** 2).mean()\n",
    "\n",
    "class OurNeuralNetwork:\n",
    "  '''\n",
    "  A neural network with:\n",
    "    - 2 inputs\n",
    "    - a hidden layer with 2 neurons (h1, h2)\n",
    "    - an output layer with 1 neuron (o1)\n",
    "  '''\n",
    "  def __init__(self):\n",
    "    # Weights\n",
    "    self.w0 = np.random.randn(2, 2)\n",
    "    self.w1 = np.random.randn(2, 1)\n",
    "\n",
    "    # Biases\n",
    "    self.b0 = np.random.randn(1, 2)\n",
    "    self.b1 = np.random.randn(1, 1)\n",
    "\n",
    "  def feedforward(self, x):\n",
    "      # x is a numpy array with 2 elements#\n",
    "      h0 = sigmoid(np.dot(x, self.w0) + self.b0)\n",
    "      o0 = sigmoid(np.dot(h0, self.w1) + self.b1)\n",
    "      return o0\n",
    "\n",
    "  def train(self, data, all_y_trues):\n",
    "      '''\n",
    "      - data is a (n x 2) numpy array, n = # of samples in the dataset.\n",
    "      - all_y_trues is a numpy array with n elements.\n",
    "      Elements in all_y_trues correspond to those in data.\n",
    "      '''\n",
    "      learn_rate = 0.15\n",
    "      epochs = 200 # number of times to loop through the entire dataset\n",
    "      \n",
    "      for epoch in range(epochs):\n",
    "          for x, y_true in zip(data, all_y_trues):\n",
    "              # --- Do a feedforward (we'll need these values later)\n",
    "              y_pred = self.feedforward(x)\n",
    "\n",
    "              # backpropagation\n",
    "              d_L_d_ypred = -2 * (y_true - y_pred)  # (1,2)\n",
    "              h0pre = np.dot(x, self.w0) + self.b0\n",
    "              h0 = sigmoid(h0pre)\n",
    "              dL_b1 = d_L_d_ypred * deriv_sigmoid(np.dot(h0, self.w1) + self.b1)\n",
    "              dL_w1 = dL_b1 * h0.T\n",
    "              dL_b0 = dL_b1 * np.dot(deriv_sigmoid(h0pre), self.w1)  # (1,2)\n",
    "              dL_w0 = dL_b0 * x\n",
    "              \n",
    "              # --- Update weights and biases\n",
    "              self.w1 -= learn_rate * dL_w1\n",
    "              self.b1 -= learn_rate * dL_b1\n",
    "              self.w0 -= learn_rate * dL_w0\n",
    "              self.b0 -= learn_rate * dL_b0\n",
    "          # --- Calculate total loss at the end of each epoch\n",
    "          if epoch % 20 == 0:\n",
    "              y_preds = np.apply_along_axis(self.feedforward, 1, data)\n",
    "              loss = mse_loss(all_y_trues, y_preds)\n",
    "              print(\"Epoch %d loss: %.3f\" % (epoch, loss))\n",
    "\n",
    "# training dataset\n",
    "data = np.array([\n",
    "  [-2, -1],  # Alice\n",
    "  [25, 6],   # Bob\n",
    "  [17, 4],   # Charlie\n",
    "  [-15, -6], # Diana\n",
    "])\n",
    "\n",
    "all_y_trues = np.array([\n",
    "  1, # Alice\n",
    "  0, # Bob\n",
    "  0, # Charlie\n",
    "  1, # Diana\n",
    "])\n",
    "\n",
    "start = time.time()\n",
    "# Train our neural network!\n",
    "network = OurNeuralNetwork()\n",
    "network.train(data, all_y_trues)\n",
    "end = time.time()\n",
    "print(f\"execution time: {(end-start) * 10**3} ms\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "234419db-5ce5-497a-baa8-b5c69c73ecfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Emily: [[0.89358812]]\n",
      "Frank: [[0.08016857]]\n"
     ]
    }
   ],
   "source": [
    "# Make some predictions\n",
    "emily = np.array([-7, -3])\n",
    "frank = np.array([20, 2]) \n",
    "print(f\"Emily: {network.feedforward(emily)}\")\n",
    "print(f\"Frank: {network.feedforward(frank)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abc8686a-f1d3-4c48-904a-06dc3c727916",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf-gpu",
   "language": "python",
   "name": "tf-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
